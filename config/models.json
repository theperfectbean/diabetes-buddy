{
  "models": {
    "openai": {
      "_note": "OpenAI models - not yet implemented, coming soon",
      "gpt-4-turbo": {
        "context_window": 128000,
        "max_output_tokens": 4096,
        "supports_embeddings": false,
        "supports_file_upload": true,
        "supports_vision": true,
        "cost_per_million_input_tokens": 10.00,
        "cost_per_million_output_tokens": 30.00,
        "description": "Most capable GPT-4 model with vision support.",
        "recommended": true
      },
      "gpt-4o": {
        "context_window": 128000,
        "max_output_tokens": 4096,
        "supports_embeddings": false,
        "supports_file_upload": true,
        "supports_vision": true,
        "cost_per_million_input_tokens": 5.00,
        "cost_per_million_output_tokens": 15.00,
        "description": "Optimized GPT-4 with faster response times.",
        "recommended": true
      },
      "text-embedding-3-large": {
        "context_window": 8191,
        "max_output_tokens": null,
        "supports_embeddings": true,
        "supports_file_upload": false,
        "supports_vision": false,
        "cost_per_million_input_tokens": 0.13,
        "cost_per_million_output_tokens": null,
        "description": "High-quality embeddings (3072 dimensions).",
        "recommended": true,
        "embedding_dimension": 3072
      }
    },
    "anthropic": {
      "_note": "Anthropic models - not yet implemented, coming soon",
      "claude-3-5-sonnet-20241022": {
        "context_window": 200000,
        "max_output_tokens": 8192,
        "supports_embeddings": false,
        "supports_file_upload": true,
        "supports_vision": true,
        "cost_per_million_input_tokens": 3.00,
        "cost_per_million_output_tokens": 15.00,
        "description": "Most capable Claude model. Excellent for complex reasoning and writing.",
        "recommended": true
      },
      "claude-3-5-haiku-20241022": {
        "context_window": 200000,
        "max_output_tokens": 8192,
        "supports_embeddings": false,
        "supports_file_upload": true,
        "supports_vision": true,
        "cost_per_million_input_tokens": 1.00,
        "cost_per_million_output_tokens": 5.00,
        "description": "Fast and affordable Claude model.",
        "recommended": true
      }
    },
    "groq": {
      "gpt-oss-20b": {
        "context_window": 128000,
        "max_output_tokens": 8192,
        "supports_embeddings": false,
        "supports_file_upload": false,
        "supports_vision": false,
        "cost_per_million_input_tokens": 0.075,
        "cost_per_million_output_tokens": 0.30,
        "description": "Fast open-source 20B model via Groq. Excellent for quick responses.",
        "recommended": true,
        "speed_tokens_per_second": 1000,
        "use_cases": ["device_manual", "simple_factual", "quick_responses", "general_diabetes_education"],
        "supports_prompt_caching": true,
        "prompt_caching_input_discount": 0.5
      },
      "gpt-oss-120b": {
        "context_window": 128000,
        "max_output_tokens": 8192,
        "supports_embeddings": false,
        "supports_file_upload": false,
        "supports_vision": false,
        "cost_per_million_input_tokens": 0.15,
        "cost_per_million_output_tokens": 0.60,
        "description": "Powerful 120B model via Groq. Best for complex analysis and synthesis.",
        "recommended": true,
        "speed_tokens_per_second": 500,
        "use_cases": ["glooko_analysis", "clinical_synthesis", "knowledge_base_integration", "multi_source_queries"],
        "supports_prompt_caching": true,
        "prompt_caching_input_discount": 0.5
      }
    },
    "ollama": {
      "_note": "Local Ollama models - not yet implemented, coming soon",
      "llama3.3": {
        "context_window": 128000,
        "max_output_tokens": 8192,
        "supports_embeddings": false,
        "supports_file_upload": false,
        "supports_vision": false,
        "cost_per_million_input_tokens": 0.00,
        "cost_per_million_output_tokens": 0.00,
        "description": "Free local model. Requires Ollama installation.",
        "recommended": true
      },
      "nomic-embed-text": {
        "context_window": 8192,
        "max_output_tokens": null,
        "supports_embeddings": true,
        "supports_file_upload": false,
        "supports_vision": false,
        "cost_per_million_input_tokens": 0.00,
        "cost_per_million_output_tokens": null,
        "description": "Free local embeddings model (768 dimensions).",
        "recommended": true,
        "embedding_dimension": 768
      }
    }
  },
  "provider_features": {
    "openai": {
      "file_upload": true,
      "vision": true,
      "embeddings": true,
      "streaming": true,
      "function_calling": true,
      "max_file_size_mb": 512,
      "supported_file_types": ["pdf", "txt", "csv", "json", "png", "jpg", "jpeg", "webp"]
    },
    "anthropic": {
      "file_upload": true,
      "vision": true,
      "embeddings": false,
      "streaming": true,
      "function_calling": false,
      "max_file_size_mb": 10,
      "supported_file_types": ["pdf", "txt", "csv", "json", "png", "jpg", "jpeg", "webp"]
    },
    "groq": {
      "file_upload": false,
      "vision": false,
      "embeddings": false,
      "streaming": true,
      "function_calling": false,
      "max_file_size_mb": 0,
      "supported_file_types": []
    },
    "ollama": {
      "file_upload": false,
      "vision": false,
      "embeddings": true,
      "streaming": true,
      "function_calling": false,
      "max_file_size_mb": 0,
      "supported_file_types": []
    }
  },
  "usage_recommendations": {
    "query_classification": {
      "recommended_model": "gpt-oss-20b",
      "alternative_models": ["gpt-oss-120b"],
      "notes": "Fast Groq model works best for lightweight classification tasks"
    },
    "document_search": {
      "recommended_model": "gpt-oss-20b",
      "alternative_models": ["gpt-oss-120b"],
      "notes": "Groq 20B handles short classification and routing prompts well"
    },
    "answer_synthesis": {
      "recommended_model": "gpt-oss-120b",
      "alternative_models": ["gpt-oss-20b"],
      "notes": "Use Groq 120B for deeper synthesis and analysis"
    },
    "embeddings": {
      "recommended_model": "sentence-transformers (local)",
      "alternative_models": ["nomic-embed-text"],
      "notes": "Local embeddings via sentence-transformers for Groq-only workflows"
    }
  },
  "metadata": {
    "last_updated": "2026-01-28",
    "version": "1.0.0",
    "notes": [
      "Costs are approximate and may change. Check provider websites for current pricing.",
      "Context windows are maximum values. Actual usable context may be lower.",
      "Models marked as not implemented are planned for future releases."
    ]
  }
}
